# Kopi Debate API

API base con **FastAPI** para el challenge de Kavak.  
Este repo contiene la √∫tlima versi√≥n del esqueleto de la aplicaci√≥n.

---

## üöÄ Requisitos del sistema

- Python 3.12
- Docker 25.x + Docker Compose v2.x
- Git 2.43 o superior

---

## ‚öôÔ∏è Instalaci√≥n y ejecuci√≥n en local

Clonar el repo y entrar a la carpeta:

```bash
git clone https://github.com/JAlbertoAlonso/kopi-chatbot.git
cd kopi-chatbot
```

Crear y activar entorno virtual:

```bash
python -m venv .venv
.\.venv\Scripts\activate   # Windows
# source .venv/bin/activate   # Linux/Mac
```

Instalar dependencias:

```bash
pip install -r requirements.txt
```

Ejecutar el servidor local con Uvicorn:

```bash
uvicorn app.main:app --reload
```

---

## üì° Endpoints iniciales

- Home ‚Üí http://127.0.0.1:8000/  
  ```json
    {"ok": true, "msg": "Hello world :) | FastAPI est√° corriendo üëã"}
  ```

- Health ‚Üí http://127.0.0.1:8000/health  
  ```json
    {"status": "healthy"}
  ```

- Docs (Swagger) ‚Üí http://127.0.0.1:8000/docs

- Chatbot ‚Üí http://127.0.0.1:8000/chat

Request:
```json
    {
  "conversation_id": null,
  "message": "Hola, ¬øqu√© tal?"
}
```

Response:
```json
    {
  "conversation_id": "uuid",
  "message": [
    {"role": "user", "message": "Hola, ¬øqu√© tal?"},
    {"role": "assistant", "message": "¬°Hola! Estoy aqu√≠ para ayudarte, ¬øen qu√© puedo asistirte hoy?"}
  ],
  "engine": "gpt-3.5-turbo"
}
```

---

## üì¶ Dependencias iniciales

- fastapi==0.111.1 ‚Äì framework principal  
- uvicorn[standard]==0.30.3 ‚Äì servidor ASGI 
- python-dotenv==1.1.1 ‚Äì manejo de variables de entorno
- openai==1.107.0 ‚Äì cliente oficial de OpenAI
- pytest==8.3.3 ‚Äì testing unitario
- sqlalchemy[asyncio]==2.x ‚Äì ORM para persistencia
- psycopg[binary]==3.x ‚Äì driver para Postgres

---

## üîë Variables de entorno

Crear un archivo .env en la ra√≠z del proyecto con:
```env
OPENAI_API_KEY=tu_api_key_aqu√≠
ENGINE=gpt-3.5-turbo
```

‚ö†Ô∏è La API utiliza GPT de OpenAI como motor. Por seguridad no se incluye ninguna API Key en el repo; cada usuario debe configurar la suya con cr√©dito disponible.  
üëâ Si lo prefieren, puedo hacerles una demo con mi propia API Key en una reuni√≥n en l√≠nea.

```env
OPENAI_API_KEY=tu_api_key_aqu√≠
ENGINE=gpt-3.5-turbo


# üëá Importante para conexi√≥n interna con Docker
DATABASE_URL=postgresql+asyncpg://kopi:kopi_password@db:5432/kopi_chat
```

‚ö†Ô∏è La API utiliza GPT de OpenAI como motor.  
‚ö†Ô∏è **Nota cr√≠tica:** dentro del contenedor la DB se llama `db` (no `localhost`).  
Si pones `localhost`, la API no podr√° conectarse a Postgres y los mensajes no se guardar√°n.

---

## üóÑÔ∏è Variables de entorno para Postgres

Existen dos formas de conexi√≥n: **modo local (contenedores)** y **modo remoto (Render u otro servicio en la nube)**.

### Con contenedores internos
```env
POSTGRES_USER=kopi_user
POSTGRES_PASSWORD=kopi_password
POSTGRES_DB=kopi_db
POSTGRES_PORT=5432

# üîë Esta URL es la que usar√° la API
DATABASE_URL=postgresql+asyncpg://kopi:kopi_password@db:5432/kopi_chat
```

### Con DB remota (ej. Render)
```env
DATABASE_URL=postgresql+psycopg://USER:PASSWORD@HOST:PORT/DBNAME
```

---

## üóÑÔ∏è Persistencia y datos iniciales en la DB

- En local (Docker):
La base de datos se levanta en un contenedor de **PostgreSQL** con persistencia habilitada.  
Los datos se almacenan en el volumen `pg_data`, lo que significa que aunque se detengan los contenedores o se reinicie el sistema, la informaci√≥n en la base de datos se conservar√°.

Al ejecutarse por primera vez, Docker inicializa el esquema definido en `scripts/ddl.sql` y adem√°s carga una conversaci√≥n de ejemplo mediante `scripts/seed.sql`.  
El prop√≥sito de este *seed* es √∫nicamente **validar que la DB est√° funcional y admite registros**. A partir de ah√≠, todas las conversaciones generadas por la API quedar√°n guardadas de forma persistente en el volumen.

- En remoto (Render):  
  La app usa un `lifespan` que asegura la **idempotencia** al crear tablas (`create_all`).  
  Esto significa que, si ya existen, no se duplican ni borran.  
  As√≠ se garantiza que la API puede correr sin errores en despliegues cloud.  
  ‚ö†Ô∏è Esto **no interfiere** con contenedores locales, porque Docker sigue aplicando los `ddl.sql` al levantar.

---

## üê≥ Levantar con Docker y Makefile

En lugar de configurar todo manualmente, puedes levantar la API y la base de datos directamente con Docker Compose y los comandos del Makefile.

‚ö†Ô∏è Aseg√∫rate de que tu .env tenga:
```env
DATABASE_URL=postgresql+asyncpg://kopi:kopi_password@db:5432/kopi_chat
```
antes de correr make up.
Esto garantiza que la API se conecte al contenedor de Postgres y que la persistencia funcione correctamente.

### Comandos principales

- Levantar servicios (API + DB):
  ```bash
  make up
  ```

- Apagar servicios:
  ```bash
  make down
  ```

- Ver logs:
  ```bash
  make logs-api   # Logs de la API
  make logs-db    # Logs de la base de datos
  ```

- Entrar a PostgreSQL (psql):
  ```bash
  make psql
  ```

- Reconstruir im√°genes desde cero:
  ```bash
  make build
  ```

- Volcar estado de las tablas:
  ```bash
  make db-tables
  ```

- Prueba de llamada a API e inserci√≥n de mensajes en DB:
  ```bash
  make test-api-db
  ```

---

## üß™ Pruebas

La suite de tests est√° construida con **pytest** y cubre los aspectos clave del challenge:

- Persistencia en DB (creaci√≥n de conversaciones y guardado de mensajes).
- Resiliencia al fallo del LLM (fallback).
- Trimming del historial (interno y externo).
- Performance bajo carga ligera.

### Comandos disponibles con Makefile

- Ejecutar **todas las pruebas**:  
  ```bash
  make tests-all
  ```

- Alias r√°pido para correr toda la suite:  
  ```bash
  make test
  ```

- Ejecutar **solo persistencia en DB**:  
  ```bash
  make tests-api-db
  ```

- Ejecutar **solo fallback** (cuando el LLM falla):  
  ```bash
  make tests-fallback
  ```

- Ejecutar **solo trimming** (historial 5x5 en API y LLM):  
  ```bash
  make tests-trimming
  ```

- Ejecutar **solo performance** (respuesta <5s e inclusi√≥n de metadata del LLM):  
  ```bash
  make tests-performance
  ```

---

## üèóÔ∏è Decisiones de arquitectura

- **FastAPI**: elegido por su rendimiento y facilidad de documentaci√≥n con OpenAPI.  
- **Postgres + SQLAlchemy**: garantiza persistencia y consistencia en el historial de conversaciones.  
- **Trimming (5x5)**:  
  - Se aplica en las **respuestas de la API** para cumplir con las especificaciones del challenge.  
  - Se aplica en las **llamadas al LLM** para optimizar el consumo de tokens en la API de OpenAI.  
  - En la **DB se conserva todo el historial completo**, sin recortes.  
- **Fallback seguro**: en caso de error del LLM, la API devuelve y persiste un mensaje de fallback como `assistant`, manteniendo la coherencia de la conversaci√≥n.  
- **Idempotencia en creaci√≥n de tablas (lifespan)**:  
  - Con `Base.metadata.create_all` las tablas se crean si no existen.  
  - Esto evita fallos en despliegues cloud y no afecta al flujo con contenedores locales (que ya tienen su propio init con SQL). 
