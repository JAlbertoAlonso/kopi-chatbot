from fastapi import FastAPI
from uuid import uuid4
from typing import Dict, List

from app.schemas import ChatRequest, ChatResponse, MessageTurn
from app.llm import ask_llm

# Inicializamos la aplicaci칩n FastAPI
# El t칤tulo y la versi칩n aparecer치n en la documentaci칩n autom치tica (Swagger)
app = FastAPI(title="Kopi Debate API", version="0.2.0")

# Almacenamiento temporal en memoria RAM
# conversations = { conversation_id (str): [lista de turnos MessageTurn] }
# 丘멆잺 Nota: esto se reinicia si el servidor se cae. Luego migraremos a Redis.
conversations: Dict[str, List[MessageTurn]] = {}

@app.get("/")
def root():
    """
    Endpoint ra칤z para verificar que la API est치 corriendo.
    Devuelve un saludo simple.
    """
    return {"ok": True, "msg": "Hola Beto, FastAPI est치 corriendo 游녦"}

@app.get("/health")
def health():
    """
    Endpoint de healthcheck.
    Usado para verificar si la API est치 viva.
    """
    return {"status": "healthy"}


@app.post("/chat", response_model=ChatResponse)
def chat(request: ChatRequest) -> ChatResponse:
    """
    Endpoint principal del chatbot.

    Flujo:
    1. Si no se env칤a `conversation_id`, se crea una nueva conversaci칩n (UUID).
    2. Recupera el historial de la conversaci칩n o lo inicializa vac칤o.
    3. Agrega el mensaje del usuario al historial.
    4. Genera la respuesta del modelo LLM (usando `ask_llm`).
    5. Guarda el historial actualizado en memoria.
    6. Devuelve el historial completo en un objeto `ChatResponse`.

    Args:
        request (ChatRequest): JSON con:
            - `conversation_id` (opcional): ID de la conversaci칩n.
            - `message` (obligatorio): Mensaje enviado por el usuario.

    Returns:
        ChatResponse: Objeto con el `conversation_id` y la lista de turnos (user/bot).
    """
    # 1) Obtener o crear conversation_id
    conv_id: str = request.conversation_id or str(uuid4())

    # 2) Recuperar historial existente o iniciar vac칤o
    history: list[MessageTurn] = conversations.get(conv_id, [])

    # 3) Agregar mensaje del usuario
    history.append(MessageTurn(role="user", message=request.message))

    # 4) Generar respuesta del bot mediante LLM
    bot_reply: str = ask_llm(history)
    history.append(MessageTurn(role="assistant", message=bot_reply))

    # 5) Guardar historial actualizado en memoria
    conversations[conv_id] = history

    # 6) Retornar respuesta estructurada
    return ChatResponse(conversation_id=conv_id, message=history)
